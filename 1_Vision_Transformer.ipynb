{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "08_pytorch_paper_replicating_exercises.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyOhoCjGZZxrecbm76R8UJZn",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ],
   "metadata": {
    "id": "Y5H5P8EjCNGK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4214da9e-f3a8-43e6-a48c-1a33f44a9be9",
    "ExecuteTime": {
     "end_time": "2024-10-14T08:16:03.373383Z",
     "start_time": "2024-10-14T08:16:00.581643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Implementatation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T08:16:03.382886Z",
     "start_time": "2024-10-14T08:16:03.377883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, input_channels, patch_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.conv_proj = nn.Conv2d(input_channels, embedding_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.flatten = nn.Flatten(start_dim=2, end_dim=3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_proj(x)\n",
    "        x = self.flatten(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T08:16:03.587065Z",
     "start_time": "2024-10-14T08:16:03.582848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SA(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.Q = nn.Linear(input_dim, embedding_dim)\n",
    "        self.K = nn.Linear(input_dim, embedding_dim)\n",
    "        self.V = nn.Linear(input_dim, embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        q = self.Q(x)\n",
    "        k = self.K(x)\n",
    "        v = self.V(x)\n",
    "        \n",
    "        a = (q @ k.permute(0, 2, 1)) / (64 ** 0.5)\n",
    "        x = torch.softmax(a, dim=2) @ v\n",
    "        return x\n",
    "\n",
    "\n",
    "class MSA(nn.Module):\n",
    "    def __init__(self, input_dim, n_heads):\n",
    "        super().__init__()\n",
    "        self.attention_heads = nn.ModuleList([SA(input_dim, input_dim // n_heads) for _ in range(n_heads)])\n",
    "        self.linser = nn.Linear(input_dim, input_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.concat([attention_head(x) for attention_head in self.attention_heads], dim=-1)\n",
    "        x = self.linser(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T08:16:03.597399Z",
     "start_time": "2024-10-14T08:16:03.591817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MSABlock(nn.Module):\n",
    "    def __init__(self, input_dim, n_heads):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "        self.msa = MSA(input_dim, n_heads)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.msa(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, input_dim, mlp_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_dim, input_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, input_dim, mlp_dim, n_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.msa_block = MSABlock(input_dim, n_heads)\n",
    "        self.mlp_block = MLPBlock(input_dim, mlp_dim, dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.msa_block(x) + x\n",
    "        x = self.mlp_block(x) + x\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, mlp_dim, n_heads, dropout, n_layers):\n",
    "        super().__init__()\n",
    "        self.transformer_layers = nn.Sequential(\n",
    "            *[TransformerBlock(input_dim, mlp_dim, n_heads, dropout) for _ in range(n_layers)]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.transformer_layers(x)\n",
    "        cls_embedding = x[:, 0, :]\n",
    "        return cls_embedding"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T08:16:03.606235Z",
     "start_time": "2024-10-14T08:16:03.601348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, img_size, n_channels, patch_size, embedding_dim, mlp_dim, n_heads, dropout, n_layers, n_classes):\n",
    "        super().__init__()\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "        self.cls = nn.Parameter(torch.randn(1, 1, embedding_dim))\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, self.num_patches + 1, embedding_dim))\n",
    "        self.patch_embedding = PatchEmbedding(n_channels, patch_size, embedding_dim)\n",
    "        \n",
    "        self.transformer_encoder = TransformerEncoder(embedding_dim, mlp_dim, n_heads, dropout, n_layers)\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            nn.Linear(embedding_dim, n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        cls = self.cls.expand(batch_size, -1, -1)\n",
    "        patch_embeddins = self.patch_embedding(x)\n",
    "        patch_position_embeddings = torch.concat([cls, patch_embeddins], dim=1) + self.positional_encoding\n",
    "        cls_embedding = self.transformer_encoder(patch_position_embeddings)\n",
    "        logits = self.classification_head(cls_embedding)\n",
    "        return logits"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T08:16:04.729930Z",
     "start_time": "2024-10-14T08:16:03.611144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "patch_size = 16\n",
    "embedding_dim = 768\n",
    "mlp_dim = 3072\n",
    "dropout = 0.1\n",
    "n_heads = 12\n",
    "n_layers = 12\n",
    "\n",
    "vit_model = ViT(224, 3, patch_size, embedding_dim, mlp_dim, n_heads, dropout, n_layers, 1000).to(DEVICE)\n",
    "summary(vit_model, input_size=(1, 3, 224, 224), col_names=['input_size', 'output_size', 'num_params'], depth=4, device='cpu')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #\n",
       "==================================================================================================================================\n",
       "ViT                                                     [1, 3, 224, 224]          [1, 1000]                 152,064\n",
       "├─PatchEmbedding: 1-1                                   [1, 3, 224, 224]          [1, 196, 768]             --\n",
       "│    └─Conv2d: 2-1                                      [1, 3, 224, 224]          [1, 768, 14, 14]          590,592\n",
       "│    └─Flatten: 2-2                                     [1, 768, 14, 14]          [1, 768, 196]             --\n",
       "├─TransformerEncoder: 1-2                               [1, 197, 768]             [1, 768]                  --\n",
       "│    └─Sequential: 2-3                                  [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    └─TransformerBlock: 3-1                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-1                          [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-2                          [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-2                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-3                          [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-4                          [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-3                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-5                          [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-6                          [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-4                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-7                          [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-8                          [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-5                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-9                          [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-10                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-6                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-11                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-12                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-7                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-13                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-14                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-8                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-15                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-16                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-9                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-17                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-18                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-10                      [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-19                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-20                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-11                      [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-21                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-22                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-12                      [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-23                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-24                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "├─Sequential: 1-3                                       [1, 768]                  [1, 1000]                 --\n",
       "│    └─LayerNorm: 2-4                                   [1, 768]                  [1, 768]                  1,536\n",
       "│    └─Linear: 2-5                                      [1, 768]                  [1, 1000]                 769,000\n",
       "==================================================================================================================================\n",
       "Total params: 86,567,656\n",
       "Trainable params: 86,567,656\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 201.58\n",
       "==================================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 160.99\n",
       "Params size (MB): 345.66\n",
       "Estimated Total Size (MB): 507.25\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T08:16:05.649064Z",
     "start_time": "2024-10-14T08:16:04.784705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vit_torch_model = models.vit_b_16()\n",
    "summary(vit_model, input_size=(1, 3, 224, 224), col_names=['input_size', 'output_size', 'num_params'], depth=4, device='cpu')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #\n",
       "==================================================================================================================================\n",
       "ViT                                                     [1, 3, 224, 224]          [1, 1000]                 152,064\n",
       "├─PatchEmbedding: 1-1                                   [1, 3, 224, 224]          [1, 196, 768]             --\n",
       "│    └─Conv2d: 2-1                                      [1, 3, 224, 224]          [1, 768, 14, 14]          590,592\n",
       "│    └─Flatten: 2-2                                     [1, 768, 14, 14]          [1, 768, 196]             --\n",
       "├─TransformerEncoder: 1-2                               [1, 197, 768]             [1, 768]                  --\n",
       "│    └─Sequential: 2-3                                  [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    └─TransformerBlock: 3-1                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-1                          [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-2                          [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-2                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-3                          [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-4                          [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-3                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-5                          [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-6                          [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-4                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-7                          [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-8                          [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-5                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-9                          [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-10                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-6                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-11                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-12                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-7                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-13                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-14                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-8                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-15                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-16                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-9                       [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-17                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-18                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-10                      [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-19                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-20                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-11                      [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-21                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-22                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "│    │    └─TransformerBlock: 3-12                      [1, 197, 768]             [1, 197, 768]             --\n",
       "│    │    │    └─MSABlock: 4-23                         [1, 197, 768]             [1, 197, 768]             2,363,904\n",
       "│    │    │    └─MLPBlock: 4-24                         [1, 197, 768]             [1, 197, 768]             4,723,968\n",
       "├─Sequential: 1-3                                       [1, 768]                  [1, 1000]                 --\n",
       "│    └─LayerNorm: 2-4                                   [1, 768]                  [1, 768]                  1,536\n",
       "│    └─Linear: 2-5                                      [1, 768]                  [1, 1000]                 769,000\n",
       "==================================================================================================================================\n",
       "Total params: 86,567,656\n",
       "Trainable params: 86,567,656\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 201.58\n",
       "==================================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 160.99\n",
       "Params size (MB): 345.66\n",
       "Estimated Total Size (MB): 507.25\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T08:16:07.102413Z",
     "start_time": "2024-10-14T08:16:05.787244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "data_dir = Path('./data/')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR100(data_dir, train=True, download=True, transform=transform)\n",
    "train_ds, val_ds = random_split(train_ds, (TRAIN_RATIO, 1 - TRAIN_RATIO))\n",
    "val_ds.transform = transform\n",
    "test_ds = datasets.CIFAR100(data_dir, train=False, download=True, transform=transform)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:41:04.591238Z",
     "start_time": "2024-10-14T08:16:07.111212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "from src.engine import *\n",
    "\n",
    "config = dict(batch_size=32, lr=3e-4, epochs=20, dataset='CIFAR100')\n",
    "with wandb.init(project='pytorch-study', name='ViT', config=config) as run:\n",
    "    w_config = run.config\n",
    "    train_dl = DataLoader(train_ds, batch_size=w_config.batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=w_config.batch_size, shuffle=True)\n",
    "    \n",
    "    n_classes = len(train_ds.dataset.classes)\n",
    "    vit_model = ViT(224, 3, patch_size, embedding_dim, mlp_dim, n_heads, dropout, n_layers, n_classes).to(DEVICE)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(vit_model.parameters(), lr=w_config.lr)\n",
    "    \n",
    "    loss_history, acc_history = train(vit_model, train_dl, val_dl, criterion, optimizer, w_config.epochs, DEVICE, run) "
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch=20: 100%|██████████| 20/20 [6:24:43<00:00, 1154.18s/it, train_loss=1.444, train_acc=58.23%, val_loss=3.897, val_acc=22.55%]  \n"
     ]
    }
   ],
   "execution_count": 9
  }
 ]
}
