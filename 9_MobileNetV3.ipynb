{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T05:20:16.795210Z",
     "start_time": "2024-10-13T05:20:13.380200Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Implementatation",
   "id": "6728b1ca1cd1e4dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T05:20:16.807365Z",
     "start_time": "2024-10-13T05:20:16.801209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction_ratio):\n",
    "        super().__init__()\n",
    "        rounded_cahnnels = max(8, round((channels // reduction_ratio) + 8 / 2) // 8 * 8)\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.linear1 = nn.Linear(channels, rounded_cahnnels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(rounded_cahnnels, channels)\n",
    "        self.sigmoid = nn.Hardsigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        se = self.gap(x)\n",
    "        se = se.flatten(start_dim=1)\n",
    "        se = self.linear1(se)\n",
    "        se = self.relu(se)\n",
    "        se = self.linear2(se)\n",
    "        se = self.sigmoid(se)\n",
    "        se = se[..., None, None]\n",
    "        x = x * se\n",
    "        return x"
   ],
   "id": "873d5672c2c43fc7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T05:20:17.018099Z",
     "start_time": "2024-10-13T05:20:17.011640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DepthwiseSeparableConvolution(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, use_se, activation):\n",
    "        super().__init__()\n",
    "        self.depthwise_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, stride=stride, padding=(kernel_size - 1) // 2,\n",
    "                      bias=False,\n",
    "                      groups=in_channels),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU() if activation == 'RE' else nn.Hardswish(),\n",
    "        )\n",
    "        self.se_block = SEBlock(in_channels, 4) if use_se else None\n",
    "        self.seeparable_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.se_block(x) if self.se_block else x\n",
    "        x = self.seeparable_conv(x)\n",
    "        return x"
   ],
   "id": "63d7939dd7eefc63",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T05:20:17.093515Z",
     "start_time": "2024-10-13T05:20:17.025505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class InvertedResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expand_channels, kernel_size, stride, use_se, activation):\n",
    "        super().__init__()\n",
    "        self.use_skip_connection = (stride == 1 and in_channels == out_channels)\n",
    "        \n",
    "        layers = [nn.Sequential(\n",
    "            nn.Conv2d(in_channels, expand_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(expand_channels),\n",
    "            nn.ReLU() if activation == 'RE' else nn.Hardswish(),\n",
    "        )] if in_channels != expand_channels else []\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            *layers,\n",
    "            DepthwiseSeparableConvolution(expand_channels, out_channels, kernel_size, stride, use_se, activation)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.bottleneck(x)\n",
    "        bottleneck = bottleneck + x if self.use_skip_connection else bottleneck\n",
    "        return bottleneck\n",
    "\n",
    "\n",
    "x_batch = torch.randn(32, 64, 52, 52)\n",
    "print(InvertedResidualBlock(64, 32, 3, 6, 2, True, 'RE')(x_batch).shape)"
   ],
   "id": "c26d419e1df292aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 26, 26])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T05:20:17.126945Z",
     "start_time": "2024-10-13T05:20:17.118440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, 16, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Hardswish()\n",
    "        )\n",
    "        self.conv2 = InvertedResidualBlock(16, 16, 16, 3, 2, True, 'RE')\n",
    "        self.conv3 = InvertedResidualBlock(16, 24, 72, 3, 2, False, 'RE')\n",
    "        self.conv4 = InvertedResidualBlock(24, 24, 88, 3, 1, False, 'RE')\n",
    "        self.conv5 = InvertedResidualBlock(24, 40, 96, 5, 2, True, 'HS')\n",
    "        self.conv6 = InvertedResidualBlock(40, 40, 240, 5, 1, True, 'HS')\n",
    "        self.conv7 = InvertedResidualBlock(40, 40, 240, 5, 1, True, 'HS')\n",
    "        self.conv8 = InvertedResidualBlock(40, 48, 120, 5, 1, True, 'HS')\n",
    "        self.conv9 = InvertedResidualBlock(48, 48, 144, 5, 1, True, 'HS')\n",
    "        self.conv10 = InvertedResidualBlock(48, 96, 288, 5, 2, True, 'HS')\n",
    "        self.conv11 = InvertedResidualBlock(96, 96, 576, 5, 1, True, 'HS')\n",
    "        self.conv12 = InvertedResidualBlock(96, 96, 576, 5, 1, True, 'HS')\n",
    "        self.conv13 = nn.Sequential(\n",
    "            nn.Conv2d(96, 576, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(576),\n",
    "            nn.Hardswish()\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv14 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(576, 1024),\n",
    "            nn.Hardswish()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, n_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.conv13(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.conv14(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# print(MobileNetV3(3, 1000))\n",
    "# x_batch = torch.randn(32, 3, 224, 224)\n",
    "# print(MobileNetV2(3, 1000)(x_batch).shape)"
   ],
   "id": "8f6ffb7b9ada31d4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T05:20:17.307227Z",
     "start_time": "2024-10-13T05:20:17.150359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mobilenet_v3_model = MobileNetV3(3, 1000)\n",
    "summary(mobilenet_v3_model, input_size=(1, 3, 224, 224), col_names=['output_size', 'num_params', 'mult_adds'],\n",
    "        device='cpu', depth=5)\n",
    "# print(mobilenet_v3_model)"
   ],
   "id": "81c19b8e00414744",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #                   Mult-Adds\n",
       "==================================================================================================================================\n",
       "MobileNetV3                                             [1, 1000]                 --                        --\n",
       "├─Sequential: 1-1                                       [1, 16, 112, 112]         --                        --\n",
       "│    └─Conv2d: 2-1                                      [1, 16, 112, 112]         432                       5,419,008\n",
       "│    └─BatchNorm2d: 2-2                                 [1, 16, 112, 112]         32                        32\n",
       "│    └─Hardswish: 2-3                                   [1, 16, 112, 112]         --                        --\n",
       "├─InvertedResidualBlock: 1-2                            [1, 16, 56, 56]           --                        --\n",
       "│    └─Sequential: 2-4                                  [1, 16, 56, 56]           --                        --\n",
       "│    │    └─DepthwiseSeparableConvolution: 3-1          [1, 16, 56, 56]           --                        --\n",
       "│    │    │    └─Sequential: 4-1                        [1, 16, 56, 56]           --                        --\n",
       "│    │    │    │    └─Conv2d: 5-1                       [1, 16, 56, 56]           144                       451,584\n",
       "│    │    │    │    └─BatchNorm2d: 5-2                  [1, 16, 56, 56]           32                        32\n",
       "│    │    │    │    └─ReLU: 5-3                         [1, 16, 56, 56]           --                        --\n",
       "│    │    │    └─SEBlock: 4-2                           [1, 16, 56, 56]           --                        --\n",
       "│    │    │    │    └─AdaptiveAvgPool2d: 5-4            [1, 16, 1, 1]             --                        --\n",
       "│    │    │    │    └─Linear: 5-5                       [1, 8]                    136                       136\n",
       "│    │    │    │    └─ReLU: 5-6                         [1, 8]                    --                        --\n",
       "│    │    │    │    └─Linear: 5-7                       [1, 16]                   144                       144\n",
       "│    │    │    │    └─Hardsigmoid: 5-8                  [1, 16]                   --                        --\n",
       "│    │    │    └─Sequential: 4-3                        [1, 16, 56, 56]           --                        --\n",
       "│    │    │    │    └─Conv2d: 5-9                       [1, 16, 56, 56]           256                       802,816\n",
       "│    │    │    │    └─BatchNorm2d: 5-10                 [1, 16, 56, 56]           32                        32\n",
       "├─InvertedResidualBlock: 1-3                            [1, 24, 28, 28]           --                        --\n",
       "│    └─Sequential: 2-5                                  [1, 24, 28, 28]           --                        --\n",
       "│    │    └─Sequential: 3-2                             [1, 72, 56, 56]           --                        --\n",
       "│    │    │    └─Conv2d: 4-4                            [1, 72, 56, 56]           1,152                     3,612,672\n",
       "│    │    │    └─BatchNorm2d: 4-5                       [1, 72, 56, 56]           144                       144\n",
       "│    │    │    └─ReLU: 4-6                              [1, 72, 56, 56]           --                        --\n",
       "│    │    └─DepthwiseSeparableConvolution: 3-3          [1, 24, 28, 28]           --                        --\n",
       "│    │    │    └─Sequential: 4-7                        [1, 72, 28, 28]           --                        --\n",
       "│    │    │    │    └─Conv2d: 5-11                      [1, 72, 28, 28]           648                       508,032\n",
       "│    │    │    │    └─BatchNorm2d: 5-12                 [1, 72, 28, 28]           144                       144\n",
       "│    │    │    │    └─ReLU: 5-13                        [1, 72, 28, 28]           --                        --\n",
       "│    │    │    └─Sequential: 4-8                        [1, 24, 28, 28]           --                        --\n",
       "│    │    │    │    └─Conv2d: 5-14                      [1, 24, 28, 28]           1,728                     1,354,752\n",
       "│    │    │    │    └─BatchNorm2d: 5-15                 [1, 24, 28, 28]           48                        48\n",
       "├─InvertedResidualBlock: 1-4                            [1, 24, 28, 28]           --                        --\n",
       "│    └─Sequential: 2-6                                  [1, 24, 28, 28]           --                        --\n",
       "│    │    └─Sequential: 3-4                             [1, 88, 28, 28]           --                        --\n",
       "│    │    │    └─Conv2d: 4-9                            [1, 88, 28, 28]           2,112                     1,655,808\n",
       "│    │    │    └─BatchNorm2d: 4-10                      [1, 88, 28, 28]           176                       176\n",
       "│    │    │    └─ReLU: 4-11                             [1, 88, 28, 28]           --                        --\n",
       "│    │    └─DepthwiseSeparableConvolution: 3-5          [1, 24, 28, 28]           --                        --\n",
       "│    │    │    └─Sequential: 4-12                       [1, 88, 28, 28]           --                        --\n",
       "│    │    │    │    └─Conv2d: 5-16                      [1, 88, 28, 28]           792                       620,928\n",
       "│    │    │    │    └─BatchNorm2d: 5-17                 [1, 88, 28, 28]           176                       176\n",
       "│    │    │    │    └─ReLU: 5-18                        [1, 88, 28, 28]           --                        --\n",
       "│    │    │    └─Sequential: 4-13                       [1, 24, 28, 28]           --                        --\n",
       "│    │    │    │    └─Conv2d: 5-19                      [1, 24, 28, 28]           2,112                     1,655,808\n",
       "│    │    │    │    └─BatchNorm2d: 5-20                 [1, 24, 28, 28]           48                        48\n",
       "├─InvertedResidualBlock: 1-5                            [1, 40, 14, 14]           --                        --\n",
       "│    └─Sequential: 2-7                                  [1, 40, 14, 14]           --                        --\n",
       "│    │    └─Sequential: 3-6                             [1, 96, 28, 28]           --                        --\n",
       "│    │    │    └─Conv2d: 4-14                           [1, 96, 28, 28]           2,304                     1,806,336\n",
       "│    │    │    └─BatchNorm2d: 4-15                      [1, 96, 28, 28]           192                       192\n",
       "│    │    │    └─Hardswish: 4-16                        [1, 96, 28, 28]           --                        --\n",
       "│    │    └─DepthwiseSeparableConvolution: 3-7          [1, 40, 14, 14]           --                        --\n",
       "│    │    │    └─Sequential: 4-17                       [1, 96, 14, 14]           --                        --\n",
       "│    │    │    │    └─Conv2d: 5-21                      [1, 96, 14, 14]           2,400                     470,400\n",
       "│    │    │    │    └─BatchNorm2d: 5-22                 [1, 96, 14, 14]           192                       192\n",
       "│    │    │    │    └─Hardswish: 5-23                   [1, 96, 14, 14]           --                        --\n",
       "│    │    │    └─SEBlock: 4-18                          [1, 96, 14, 14]           --                        --\n",
       "│    │    │    │    └─AdaptiveAvgPool2d: 5-24           [1, 96, 1, 1]             --                        --\n",
       "│    │    │    │    └─Linear: 5-25                      [1, 24]                   2,328                     2,328\n",
       "│    │    │    │    └─ReLU: 5-26                        [1, 24]                   --                        --\n",
       "│    │    │    │    └─Linear: 5-27                      [1, 96]                   2,400                     2,400\n",
       "│    │    │    │    └─Hardsigmoid: 5-28                 [1, 96]                   --                        --\n",
       "│    │    │    └─Sequential: 4-19                       [1, 40, 14, 14]           --                        --\n",
       "│    │    │    │    └─Conv2d: 5-29                      [1, 40, 14, 14]           3,840                     752,640\n",
       "│    │    │    │    └─BatchNorm2d: 5-30                 [1, 40, 14, 14]           80                        80\n",
       "├─InvertedResidualBlock: 1-6                            [1, 40, 14, 14]           --                        --\n",
       "│    └─Sequential: 2-8                                  [1, 40, 14, 14]           --                        --\n",
       "│    │    └─Sequential: 3-8                             [1, 240, 14, 14]          --                        --\n",
       "│    │    │    └─Conv2d: 4-20                           [1, 240, 14, 14]          9,600                     1,881,600\n",
       "│    │    │    └─BatchNorm2d: 4-21                      [1, 240, 14, 14]          480                       480\n",
       "│    │    │    └─Hardswish: 4-22                        [1, 240, 14, 14]          --                        --\n",
       "│    │    └─DepthwiseSeparableConvolution: 3-9          [1, 40, 14, 14]           --                        --\n",
       "│    │    │    └─Sequential: 4-23                       [1, 240, 14, 14]          --                        --\n",
       "│    │    │    │    └─Conv2d: 5-31                      [1, 240, 14, 14]          6,000                     1,176,000\n",
       "│    │    │    │    └─BatchNorm2d: 5-32                 [1, 240, 14, 14]          480                       480\n",
       "│    │    │    │    └─Hardswish: 5-33                   [1, 240, 14, 14]          --                        --\n",
       "│    │    │    └─SEBlock: 4-24                          [1, 240, 14, 14]          --                        --\n",
       "│    │    │    │    └─AdaptiveAvgPool2d: 5-34           [1, 240, 1, 1]            --                        --\n",
       "│    │    │    │    └─Linear: 5-35                      [1, 64]                   15,424                    15,424\n",
       "│    │    │    │    └─ReLU: 5-36                        [1, 64]                   --                        --\n",
       "│    │    │    │    └─Linear: 5-37                      [1, 240]                  15,600                    15,600\n",
       "│    │    │    │    └─Hardsigmoid: 5-38                 [1, 240]                  --                        --\n",
       "│    │    │    └─Sequential: 4-25                       [1, 40, 14, 14]           --                        --\n",
       "│    │    │    │    └─Conv2d: 5-39                      [1, 40, 14, 14]           9,600                     1,881,600\n",
       "│    │    │    │    └─BatchNorm2d: 5-40                 [1, 40, 14, 14]           80                        80\n",
       "├─InvertedResidualBlock: 1-7                            [1, 40, 14, 14]           --                        --\n",
       "│    └─Sequential: 2-9                                  [1, 40, 14, 14]           --                        --\n",
       "│    │    └─Sequential: 3-10                            [1, 240, 14, 14]          --                        --\n",
       "│    │    │    └─Conv2d: 4-26                           [1, 240, 14, 14]          9,600                     1,881,600\n",
       "│    │    │    └─BatchNorm2d: 4-27                      [1, 240, 14, 14]          480                       480\n",
       "│    │    │    └─Hardswish: 4-28                        [1, 240, 14, 14]          --                        --\n",
       "│    │    └─DepthwiseSeparableConvolution: 3-11         [1, 40, 14, 14]           --                        --\n",
       "│    │    │    └─Sequential: 4-29                       [1, 240, 14, 14]          --                        --\n",
       "│    │    │    │    └─Conv2d: 5-41                      [1, 240, 14, 14]          6,000                     1,176,000\n",
       "│    │    │    │    └─BatchNorm2d: 5-42                 [1, 240, 14, 14]          480                       480\n",
       "│    │    │    │    └─Hardswish: 5-43                   [1, 240, 14, 14]          --                        --\n",
       "│    │    │    └─SEBlock: 4-30                          [1, 240, 14, 14]          --                        --\n",
       "│    │    │    │    └─AdaptiveAvgPool2d: 5-44           [1, 240, 1, 1]            --                        --\n",
       "│    │    │    │    └─Linear: 5-45                      [1, 64]                   15,424                    15,424\n",
       "│    │    │    │    └─ReLU: 5-46                        [1, 64]                   --                        --\n",
       "│    │    │    │    └─Linear: 5-47                      [1, 240]                  15,600                    15,600\n",
       "│    │    │    │    └─Hardsigmoid: 5-48                 [1, 240]                  --                        --\n",
       "│    │    │    └─Sequential: 4-31                       [1, 40, 14, 14]           --                        --\n",
       "│    │    │    │    └─Conv2d: 5-49                      [1, 40, 14, 14]           9,600                     1,881,600\n",
       "│    │    │    │    └─BatchNorm2d: 5-50                 [1, 40, 14, 14]           80                        80\n",
       "├─InvertedResidualBlock: 1-8                            [1, 48, 14, 14]           --                        --\n",
       "│    └─Sequential: 2-10                                 [1, 48, 14, 14]           --                        --\n",
       "│    │    └─Sequential: 3-12                            [1, 120, 14, 14]          --                        --\n",
       "│    │    │    └─Conv2d: 4-32                           [1, 120, 14, 14]          4,800                     940,800\n",
       "│    │    │    └─BatchNorm2d: 4-33                      [1, 120, 14, 14]          240                       240\n",
       "│    │    │    └─Hardswish: 4-34                        [1, 120, 14, 14]          --                        --\n",
       "│    │    └─DepthwiseSeparableConvolution: 3-13         [1, 48, 14, 14]           --                        --\n",
       "│    │    │    └─Sequential: 4-35                       [1, 120, 14, 14]          --                        --\n",
       "│    │    │    │    └─Conv2d: 5-51                      [1, 120, 14, 14]          3,000                     588,000\n",
       "│    │    │    │    └─BatchNorm2d: 5-52                 [1, 120, 14, 14]          240                       240\n",
       "│    │    │    │    └─Hardswish: 5-53                   [1, 120, 14, 14]          --                        --\n",
       "│    │    │    └─SEBlock: 4-36                          [1, 120, 14, 14]          --                        --\n",
       "│    │    │    │    └─AdaptiveAvgPool2d: 5-54           [1, 120, 1, 1]            --                        --\n",
       "│    │    │    │    └─Linear: 5-55                      [1, 32]                   3,872                     3,872\n",
       "│    │    │    │    └─ReLU: 5-56                        [1, 32]                   --                        --\n",
       "│    │    │    │    └─Linear: 5-57                      [1, 120]                  3,960                     3,960\n",
       "│    │    │    │    └─Hardsigmoid: 5-58                 [1, 120]                  --                        --\n",
       "│    │    │    └─Sequential: 4-37                       [1, 48, 14, 14]           --                        --\n",
       "│    │    │    │    └─Conv2d: 5-59                      [1, 48, 14, 14]           5,760                     1,128,960\n",
       "│    │    │    │    └─BatchNorm2d: 5-60                 [1, 48, 14, 14]           96                        96\n",
       "├─InvertedResidualBlock: 1-9                            [1, 48, 14, 14]           --                        --\n",
       "│    └─Sequential: 2-11                                 [1, 48, 14, 14]           --                        --\n",
       "│    │    └─Sequential: 3-14                            [1, 144, 14, 14]          --                        --\n",
       "│    │    │    └─Conv2d: 4-38                           [1, 144, 14, 14]          6,912                     1,354,752\n",
       "│    │    │    └─BatchNorm2d: 4-39                      [1, 144, 14, 14]          288                       288\n",
       "│    │    │    └─Hardswish: 4-40                        [1, 144, 14, 14]          --                        --\n",
       "│    │    └─DepthwiseSeparableConvolution: 3-15         [1, 48, 14, 14]           --                        --\n",
       "│    │    │    └─Sequential: 4-41                       [1, 144, 14, 14]          --                        --\n",
       "│    │    │    │    └─Conv2d: 5-61                      [1, 144, 14, 14]          3,600                     705,600\n",
       "│    │    │    │    └─BatchNorm2d: 5-62                 [1, 144, 14, 14]          288                       288\n",
       "│    │    │    │    └─Hardswish: 5-63                   [1, 144, 14, 14]          --                        --\n",
       "│    │    │    └─SEBlock: 4-42                          [1, 144, 14, 14]          --                        --\n",
       "│    │    │    │    └─AdaptiveAvgPool2d: 5-64           [1, 144, 1, 1]            --                        --\n",
       "│    │    │    │    └─Linear: 5-65                      [1, 40]                   5,800                     5,800\n",
       "│    │    │    │    └─ReLU: 5-66                        [1, 40]                   --                        --\n",
       "│    │    │    │    └─Linear: 5-67                      [1, 144]                  5,904                     5,904\n",
       "│    │    │    │    └─Hardsigmoid: 5-68                 [1, 144]                  --                        --\n",
       "│    │    │    └─Sequential: 4-43                       [1, 48, 14, 14]           --                        --\n",
       "│    │    │    │    └─Conv2d: 5-69                      [1, 48, 14, 14]           6,912                     1,354,752\n",
       "│    │    │    │    └─BatchNorm2d: 5-70                 [1, 48, 14, 14]           96                        96\n",
       "├─InvertedResidualBlock: 1-10                           [1, 96, 7, 7]             --                        --\n",
       "│    └─Sequential: 2-12                                 [1, 96, 7, 7]             --                        --\n",
       "│    │    └─Sequential: 3-16                            [1, 288, 14, 14]          --                        --\n",
       "│    │    │    └─Conv2d: 4-44                           [1, 288, 14, 14]          13,824                    2,709,504\n",
       "│    │    │    └─BatchNorm2d: 4-45                      [1, 288, 14, 14]          576                       576\n",
       "│    │    │    └─Hardswish: 4-46                        [1, 288, 14, 14]          --                        --\n",
       "│    │    └─DepthwiseSeparableConvolution: 3-17         [1, 96, 7, 7]             --                        --\n",
       "│    │    │    └─Sequential: 4-47                       [1, 288, 7, 7]            --                        --\n",
       "│    │    │    │    └─Conv2d: 5-71                      [1, 288, 7, 7]            7,200                     352,800\n",
       "│    │    │    │    └─BatchNorm2d: 5-72                 [1, 288, 7, 7]            576                       576\n",
       "│    │    │    │    └─Hardswish: 5-73                   [1, 288, 7, 7]            --                        --\n",
       "│    │    │    └─SEBlock: 4-48                          [1, 288, 7, 7]            --                        --\n",
       "│    │    │    │    └─AdaptiveAvgPool2d: 5-74           [1, 288, 1, 1]            --                        --\n",
       "│    │    │    │    └─Linear: 5-75                      [1, 72]                   20,808                    20,808\n",
       "│    │    │    │    └─ReLU: 5-76                        [1, 72]                   --                        --\n",
       "│    │    │    │    └─Linear: 5-77                      [1, 288]                  21,024                    21,024\n",
       "│    │    │    │    └─Hardsigmoid: 5-78                 [1, 288]                  --                        --\n",
       "│    │    │    └─Sequential: 4-49                       [1, 96, 7, 7]             --                        --\n",
       "│    │    │    │    └─Conv2d: 5-79                      [1, 96, 7, 7]             27,648                    1,354,752\n",
       "│    │    │    │    └─BatchNorm2d: 5-80                 [1, 96, 7, 7]             192                       192\n",
       "├─InvertedResidualBlock: 1-11                           [1, 96, 7, 7]             --                        --\n",
       "│    └─Sequential: 2-13                                 [1, 96, 7, 7]             --                        --\n",
       "│    │    └─Sequential: 3-18                            [1, 576, 7, 7]            --                        --\n",
       "│    │    │    └─Conv2d: 4-50                           [1, 576, 7, 7]            55,296                    2,709,504\n",
       "│    │    │    └─BatchNorm2d: 4-51                      [1, 576, 7, 7]            1,152                     1,152\n",
       "│    │    │    └─Hardswish: 4-52                        [1, 576, 7, 7]            --                        --\n",
       "│    │    └─DepthwiseSeparableConvolution: 3-19         [1, 96, 7, 7]             --                        --\n",
       "│    │    │    └─Sequential: 4-53                       [1, 576, 7, 7]            --                        --\n",
       "│    │    │    │    └─Conv2d: 5-81                      [1, 576, 7, 7]            14,400                    705,600\n",
       "│    │    │    │    └─BatchNorm2d: 5-82                 [1, 576, 7, 7]            1,152                     1,152\n",
       "│    │    │    │    └─Hardswish: 5-83                   [1, 576, 7, 7]            --                        --\n",
       "│    │    │    └─SEBlock: 4-54                          [1, 576, 7, 7]            --                        --\n",
       "│    │    │    │    └─AdaptiveAvgPool2d: 5-84           [1, 576, 1, 1]            --                        --\n",
       "│    │    │    │    └─Linear: 5-85                      [1, 144]                  83,088                    83,088\n",
       "│    │    │    │    └─ReLU: 5-86                        [1, 144]                  --                        --\n",
       "│    │    │    │    └─Linear: 5-87                      [1, 576]                  83,520                    83,520\n",
       "│    │    │    │    └─Hardsigmoid: 5-88                 [1, 576]                  --                        --\n",
       "│    │    │    └─Sequential: 4-55                       [1, 96, 7, 7]             --                        --\n",
       "│    │    │    │    └─Conv2d: 5-89                      [1, 96, 7, 7]             55,296                    2,709,504\n",
       "│    │    │    │    └─BatchNorm2d: 5-90                 [1, 96, 7, 7]             192                       192\n",
       "├─InvertedResidualBlock: 1-12                           [1, 96, 7, 7]             --                        --\n",
       "│    └─Sequential: 2-14                                 [1, 96, 7, 7]             --                        --\n",
       "│    │    └─Sequential: 3-20                            [1, 576, 7, 7]            --                        --\n",
       "│    │    │    └─Conv2d: 4-56                           [1, 576, 7, 7]            55,296                    2,709,504\n",
       "│    │    │    └─BatchNorm2d: 4-57                      [1, 576, 7, 7]            1,152                     1,152\n",
       "│    │    │    └─Hardswish: 4-58                        [1, 576, 7, 7]            --                        --\n",
       "│    │    └─DepthwiseSeparableConvolution: 3-21         [1, 96, 7, 7]             --                        --\n",
       "│    │    │    └─Sequential: 4-59                       [1, 576, 7, 7]            --                        --\n",
       "│    │    │    │    └─Conv2d: 5-91                      [1, 576, 7, 7]            14,400                    705,600\n",
       "│    │    │    │    └─BatchNorm2d: 5-92                 [1, 576, 7, 7]            1,152                     1,152\n",
       "│    │    │    │    └─Hardswish: 5-93                   [1, 576, 7, 7]            --                        --\n",
       "│    │    │    └─SEBlock: 4-60                          [1, 576, 7, 7]            --                        --\n",
       "│    │    │    │    └─AdaptiveAvgPool2d: 5-94           [1, 576, 1, 1]            --                        --\n",
       "│    │    │    │    └─Linear: 5-95                      [1, 144]                  83,088                    83,088\n",
       "│    │    │    │    └─ReLU: 5-96                        [1, 144]                  --                        --\n",
       "│    │    │    │    └─Linear: 5-97                      [1, 576]                  83,520                    83,520\n",
       "│    │    │    │    └─Hardsigmoid: 5-98                 [1, 576]                  --                        --\n",
       "│    │    │    └─Sequential: 4-61                       [1, 96, 7, 7]             --                        --\n",
       "│    │    │    │    └─Conv2d: 5-99                      [1, 96, 7, 7]             55,296                    2,709,504\n",
       "│    │    │    │    └─BatchNorm2d: 5-100                [1, 96, 7, 7]             192                       192\n",
       "├─Sequential: 1-13                                      [1, 576, 7, 7]            --                        --\n",
       "│    └─Conv2d: 2-15                                     [1, 576, 7, 7]            55,296                    2,709,504\n",
       "│    └─BatchNorm2d: 2-16                                [1, 576, 7, 7]            1,152                     1,152\n",
       "│    └─Hardswish: 2-17                                  [1, 576, 7, 7]            --                        --\n",
       "├─AdaptiveAvgPool2d: 1-14                               [1, 576, 1, 1]            --                        --\n",
       "├─Sequential: 1-15                                      [1, 1024]                 --                        --\n",
       "│    └─Flatten: 2-18                                    [1, 576]                  --                        --\n",
       "│    └─Linear: 2-19                                     [1, 1024]                 590,848                   590,848\n",
       "│    └─Hardswish: 2-20                                  [1, 1024]                 --                        --\n",
       "├─Sequential: 1-16                                      [1, 1000]                 --                        --\n",
       "│    └─Linear: 2-21                                     [1, 1000]                 1,025,000                 1,025,000\n",
       "==================================================================================================================================\n",
       "Total params: 2,542,856\n",
       "Trainable params: 2,542,856\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 56.53\n",
       "==================================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 22.64\n",
       "Params size (MB): 10.17\n",
       "Estimated Total Size (MB): 33.42\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T05:20:17.416543Z",
     "start_time": "2024-10-13T05:20:17.332374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mobilenet_v3_torch_model = models.mobilenet_v3_small()\n",
    "summary(mobilenet_v3_torch_model, input_size=(1, 3, 224, 224), col_names=['output_size', 'num_params', 'mult_adds'],\n",
    "        device='cpu')\n",
    "# print(mobilenet_v3_torch_model)"
   ],
   "id": "d725afd43334e3c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #                   Mult-Adds\n",
       "=============================================================================================================================\n",
       "MobileNetV3                                        [1, 1000]                 --                        --\n",
       "├─Sequential: 1-1                                  [1, 576, 7, 7]            --                        --\n",
       "│    └─Conv2dNormActivation: 2-1                   [1, 16, 112, 112]         --                        --\n",
       "│    │    └─Conv2d: 3-1                            [1, 16, 112, 112]         432                       5,419,008\n",
       "│    │    └─BatchNorm2d: 3-2                       [1, 16, 112, 112]         32                        32\n",
       "│    │    └─Hardswish: 3-3                         [1, 16, 112, 112]         --                        --\n",
       "│    └─InvertedResidual: 2-2                       [1, 16, 56, 56]           --                        --\n",
       "│    │    └─Sequential: 3-4                        [1, 16, 56, 56]           744                       1,254,744\n",
       "│    └─InvertedResidual: 2-3                       [1, 24, 28, 28]           --                        --\n",
       "│    │    └─Sequential: 3-5                        [1, 24, 28, 28]           3,864                     5,475,792\n",
       "│    └─InvertedResidual: 2-4                       [1, 24, 28, 28]           --                        --\n",
       "│    │    └─Sequential: 3-6                        [1, 24, 28, 28]           5,416                     3,932,944\n",
       "│    └─InvertedResidual: 2-5                       [1, 40, 14, 14]           --                        --\n",
       "│    │    └─Sequential: 3-7                        [1, 40, 14, 14]           13,736                    3,034,568\n",
       "│    └─InvertedResidual: 2-6                       [1, 40, 14, 14]           --                        --\n",
       "│    │    └─Sequential: 3-8                        [1, 40, 14, 14]           57,264                    4,971,264\n",
       "│    └─InvertedResidual: 2-7                       [1, 40, 14, 14]           --                        --\n",
       "│    │    └─Sequential: 3-9                        [1, 40, 14, 14]           57,264                    4,971,264\n",
       "│    └─InvertedResidual: 2-8                       [1, 48, 14, 14]           --                        --\n",
       "│    │    └─Sequential: 3-10                       [1, 48, 14, 14]           21,968                    2,666,168\n",
       "│    └─InvertedResidual: 2-9                       [1, 48, 14, 14]           --                        --\n",
       "│    │    └─Sequential: 3-11                       [1, 48, 14, 14]           29,800                    3,427,480\n",
       "│    └─InvertedResidual: 2-10                      [1, 96, 7, 7]             --                        --\n",
       "│    │    └─Sequential: 3-12                       [1, 96, 7, 7]             91,848                    4,460,232\n",
       "│    └─InvertedResidual: 2-11                      [1, 96, 7, 7]             --                        --\n",
       "│    │    └─Sequential: 3-13                       [1, 96, 7, 7]             294,096                   6,293,712\n",
       "│    └─InvertedResidual: 2-12                      [1, 96, 7, 7]             --                        --\n",
       "│    │    └─Sequential: 3-14                       [1, 96, 7, 7]             294,096                   6,293,712\n",
       "│    └─Conv2dNormActivation: 2-13                  [1, 576, 7, 7]            --                        --\n",
       "│    │    └─Conv2d: 3-15                           [1, 576, 7, 7]            55,296                    2,709,504\n",
       "│    │    └─BatchNorm2d: 3-16                      [1, 576, 7, 7]            1,152                     1,152\n",
       "│    │    └─Hardswish: 3-17                        [1, 576, 7, 7]            --                        --\n",
       "├─AdaptiveAvgPool2d: 1-2                           [1, 576, 1, 1]            --                        --\n",
       "├─Sequential: 1-3                                  [1, 1000]                 --                        --\n",
       "│    └─Linear: 2-14                                [1, 1024]                 590,848                   590,848\n",
       "│    └─Hardswish: 2-15                             [1, 1024]                 --                        --\n",
       "│    └─Dropout: 2-16                               [1, 1024]                 --                        --\n",
       "│    └─Linear: 2-17                                [1, 1000]                 1,025,000                 1,025,000\n",
       "=============================================================================================================================\n",
       "Total params: 2,542,856\n",
       "Trainable params: 2,542,856\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 56.53\n",
       "=============================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 22.64\n",
       "Params size (MB): 10.17\n",
       "Estimated Total Size (MB): 33.42\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "e2f0ce17f284d70c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T05:20:18.973492Z",
     "start_time": "2024-10-13T05:20:17.562621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "data_dir = Path('./data/')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR100(data_dir, train=True, download=True, transform=transform)\n",
    "train_ds, val_ds = random_split(train_ds, (TRAIN_RATIO, 1 - TRAIN_RATIO))\n",
    "val_ds.transform = transform\n",
    "test_ds = datasets.CIFAR100(data_dir, train=False, download=True, transform=transform)"
   ],
   "id": "42d21d784414347d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T05:22:42.019759Z",
     "start_time": "2024-10-13T05:20:19.008264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "from src.engine import *\n",
    "\n",
    "config = dict(batch_size=512, lr=3e-3, epochs=20, dataset='CIFAR100')\n",
    "with wandb.init(project='pytorch-study', name='MobileNetV3', config=config) as run:\n",
    "    w_config = run.config\n",
    "    train_dl = DataLoader(train_ds, batch_size=w_config.batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=w_config.batch_size, shuffle=True)\n",
    "    \n",
    "    n_classes = len(train_ds.dataset.classes)\n",
    "    mobilenet_v3_model = MobileNetV3(3, n_classes).to(DEVICE)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(mobilenet_v3_model.parameters(), lr=w_config.lr)\n",
    "    \n",
    "    loss_history, acc_history = train(mobilenet_v3_model, train_dl, val_dl, criterion, optimizer, w_config.epochs, DEVICE, run) "
   ],
   "id": "7feb6758495dd8a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c382be020e2d4d0d88591eee4fb89aab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch=2:   5%|▌         | 1/20 [02:11<41:33, 131.26s/it, train_loss=3.733, train_acc=11.33%, val_loss=3.414, val_acc=17.13%]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dk\\AppData\\Local\\Temp\\ipykernel_27628\\3236535813.py\", line 16, in <module>\n",
      "    loss_history, acc_history = train(mobilenet_v3_model, train_dl, val_dl, criterion, optimizer, w_config.epochs, DEVICE, run)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\OneDrive\\local\\workspace\\paper implementation\\src\\engine.py\", line 50, in train\n",
      "    train_loss, train_acc = batch_epoch(model, train_dl, criterion, device, optimizer)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\OneDrive\\local\\workspace\\paper implementation\\src\\engine.py\", line 14, in batch_epoch\n",
      "    y_logits = model(x_batch)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\AppData\\Local\\Temp\\ipykernel_27628\\3767031232.py\", line 43, in forward\n",
      "    x = self.conv8(x)\n",
      "        ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\AppData\\Local\\Temp\\ipykernel_27628\\625334549.py\", line 17, in forward\n",
      "    bottleneck = self.bottleneck(x)\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 219, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\AppData\\Local\\Temp\\ipykernel_27628\\4141361208.py\", line 37, in forward\n",
      "    x = self.seeparable_conv(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 219, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 458, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dk\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 454, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 16\u001B[0m\n\u001B[0;32m     13\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[0;32m     14\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(mobilenet_v3_model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mw_config\u001B[38;5;241m.\u001B[39mlr)\n\u001B[1;32m---> 16\u001B[0m loss_history, acc_history \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmobilenet_v3_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun\u001B[49m\u001B[43m)\u001B[49m \n",
      "File \u001B[1;32mD:\\OneDrive\\local\\workspace\\paper implementation\\src\\engine.py:50\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, train_dl, val_dl, criterion, optimizer, epochs, device, run)\u001B[0m\n\u001B[0;32m     47\u001B[0m pbar\u001B[38;5;241m.\u001B[39mset_description(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     49\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m---> 50\u001B[0m train_loss, train_acc \u001B[38;5;241m=\u001B[39m \u001B[43mbatch_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m loss_history[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(train_loss)\n\u001B[0;32m     52\u001B[0m acc_history[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(train_acc)\n",
      "File \u001B[1;32mD:\\OneDrive\\local\\workspace\\paper implementation\\src\\engine.py:14\u001B[0m, in \u001B[0;36mbatch_epoch\u001B[1;34m(model, dl, criterion, device, optimizer)\u001B[0m\n\u001B[0;32m     11\u001B[0m x_batch \u001B[38;5;241m=\u001B[39m x_batch\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     12\u001B[0m y_batch \u001B[38;5;241m=\u001B[39m y_batch\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 14\u001B[0m y_logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m y_preds \u001B[38;5;241m=\u001B[39m y_logits\u001B[38;5;241m.\u001B[39msoftmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     16\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(y_logits, y_batch)\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[5], line 43\u001B[0m, in \u001B[0;36mMobileNetV3.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     41\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv6(x)\n\u001B[0;32m     42\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv7(x)\n\u001B[1;32m---> 43\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv8\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     44\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv9(x)\n\u001B[0;32m     45\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv10(x)\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[4], line 17\u001B[0m, in \u001B[0;36mInvertedResidualBlock.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 17\u001B[0m     bottleneck \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbottleneck\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m     bottleneck \u001B[38;5;241m=\u001B[39m bottleneck \u001B[38;5;241m+\u001B[39m x \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_skip_connection \u001B[38;5;28;01melse\u001B[39;00m bottleneck\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m bottleneck\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 219\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[3], line 37\u001B[0m, in \u001B[0;36mDepthwiseSeparableConvolution.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     35\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdepthwise_conv(x)\n\u001B[0;32m     36\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mse_block(x) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mse_block \u001B[38;5;28;01melse\u001B[39;00m x\n\u001B[1;32m---> 37\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseeparable_conv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 219\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pipenv\\paper_implementation-aJVmDThZ\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    452\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    453\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 454\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
