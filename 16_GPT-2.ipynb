{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "08_pytorch_paper_replicating_exercises.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyOhoCjGZZxrecbm76R8UJZn",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ],
   "metadata": {
    "id": "Y5H5P8EjCNGK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4214da9e-f3a8-43e6-a48c-1a33f44a9be9",
    "ExecuteTime": {
     "end_time": "2024-10-15T04:46:57.047948Z",
     "start_time": "2024-10-15T04:46:57.044900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Implementatation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T04:46:57.571701Z",
     "start_time": "2024-10-15T04:46:57.527585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.Q = nn.Linear(input_dim, embedding_dim)\n",
    "        self.K = nn.Linear(input_dim, embedding_dim)\n",
    "        self.V = nn.Linear(input_dim, embedding_dim)\n",
    "    \n",
    "    def forward(self, x_q, x_k, x_v, mask=None):\n",
    "        q = self.Q(x_q)\n",
    "        k = self.K(x_k)\n",
    "        v = self.V(x_v)\n",
    "        \n",
    "        a = (q @ k.permute(0, 2, 1)) / (self.input_dim ** 0.5)\n",
    "        if mask is not None:\n",
    "            a[:, mask] = -1e10\n",
    "        x = torch.softmax(a, dim=2) @ v\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiheadSelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim, n_heads):\n",
    "        super().__init__()\n",
    "        self.attention_heads = nn.ModuleList([SelfAttention(input_dim, input_dim // n_heads) for _ in range(n_heads)])\n",
    "        self.linear = nn.Linear(input_dim, input_dim)\n",
    "    \n",
    "    def forward(self, x_q, x_k, x_v, mask=None):\n",
    "        x = torch.concat([attention_head(x_q, x_k, x_v, mask) for attention_head in self.attention_heads], dim=-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "x_batch = torch.randn(4, 100, 512)\n",
    "mask = torch.ones(100, 100).tril() == 0\n",
    "\n",
    "print(MultiheadSelfAttention(512, 16)(x_batch, x_batch, x_batch, mask=mask).shape)\n",
    "print(nn.MultiheadAttention(512, 16, batch_first=True)(x_batch, x_batch, x_batch, need_weights=False, attn_mask=mask)[0].shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100, 512])\n",
      "torch.Size([4, 100, 512])\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T04:46:57.785699Z",
     "start_time": "2024-10-15T04:46:57.781363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MSABlock(nn.Module):\n",
    "    def __init__(self, input_dim, n_heads, dropout, torch_msa=True):\n",
    "        super().__init__()\n",
    "        self.torch_msa = torch_msa\n",
    "        \n",
    "        self.msa = MultiheadSelfAttention(input_dim, n_heads) if torch_msa \\\n",
    "            else nn.MultiheadAttention(input_dim, n_heads, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x_q, x_k, x_v, mask=None):\n",
    "        x = self.msa(x_q, x_k, x_v, mask=mask) if self.torch_msa \\\n",
    "            else self.msa(x_q, x_k, x_v, need_weights=False, attn_mask=mask)[0] # mask\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, input_dim, mlp_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(input_dim, mlp_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(mlp_dim, input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T04:46:58.097472Z",
     "start_time": "2024-10-15T04:46:58.092471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, input_dim, mlp_dim, n_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.msa_block = MSABlock(input_dim, n_heads, dropout)\n",
    "        self.layer_norm1 = nn.LayerNorm(input_dim)\n",
    "        self.mlp_block = MLPBlock(input_dim, mlp_dim, dropout)\n",
    "        self.layer_norm2 = nn.LayerNorm(input_dim)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        shortcut = x\n",
    "        x = self.layer_norm1(x)\n",
    "        x = self.msa_block(x, x, x, mask) + shortcut\n",
    "        shortcut = x\n",
    "        x = self.layer_norm2(x)\n",
    "        x = self.mlp_block(x) + shortcut\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T04:46:58.554169Z",
     "start_time": "2024-10-15T04:46:58.548230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GPT2(nn.Module):\n",
    "    def __init__(self, seq_len, word_dim, embedding_dim, mlp_dim, n_heads, n_layers, n_classes, dropout):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.input_embedding = nn.Linear(word_dim, embedding_dim, bias=False)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, seq_len, embedding_dim))\n",
    "        \n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderBlock(embedding_dim, mlp_dim, n_heads, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            nn.Linear(embedding_dim, n_classes)\n",
    "        )\n",
    "    \n",
    "    def create_attention_mask(self):\n",
    "        mask = torch.ones(self.seq_len, self.seq_len).tril() == 0\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, input_seq):\n",
    "        input_embedding = self.input_embedding(input_seq) + self.positional_encoding\n",
    "        \n",
    "        mask = self.create_attention_mask()\n",
    "        decoder_out = input_embedding\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            decoder_layer(input_embedding, mask)\n",
    "        \n",
    "        logits = self.classification_head(decoder_out)\n",
    "        \n",
    "        return logits"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T04:47:03.233143Z",
     "start_time": "2024-10-15T04:46:59.353051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seq_len = 1024\n",
    "word_dim = 50257\n",
    "embedding_dim = 768\n",
    "mlp_dim = embedding_dim*4\n",
    "n_heads = 12\n",
    "n_layers = 12\n",
    "dropout = 0.1\n",
    "\n",
    "gpt2_model = GPT2(seq_len, word_dim, embedding_dim, mlp_dim, n_heads, n_layers, word_dim, dropout)\n",
    "summary(gpt2_model, input_size=(1, seq_len, word_dim), device='cpu', col_names=['output_size', 'num_params', 'mult_adds'], depth=2)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #                   Mult-Adds\n",
       "==================================================================================================================================\n",
       "GPT2                                                    [1, 1024, 50257]          786,432                   --\n",
       "├─Linear: 1-1                                           [1, 1024, 768]            38,597,376                38,597,376\n",
       "├─ModuleList: 1-2                                       --                        --                        --\n",
       "│    └─DecoderBlock: 2-1                                [1, 1024, 768]            7,087,872                 7,087,872\n",
       "│    └─DecoderBlock: 2-2                                [1, 1024, 768]            7,087,872                 7,087,872\n",
       "│    └─DecoderBlock: 2-3                                [1, 1024, 768]            7,087,872                 7,087,872\n",
       "│    └─DecoderBlock: 2-4                                [1, 1024, 768]            7,087,872                 7,087,872\n",
       "│    └─DecoderBlock: 2-5                                [1, 1024, 768]            7,087,872                 7,087,872\n",
       "│    └─DecoderBlock: 2-6                                [1, 1024, 768]            7,087,872                 7,087,872\n",
       "│    └─DecoderBlock: 2-7                                [1, 1024, 768]            7,087,872                 7,087,872\n",
       "│    └─DecoderBlock: 2-8                                [1, 1024, 768]            7,087,872                 7,087,872\n",
       "│    └─DecoderBlock: 2-9                                [1, 1024, 768]            7,087,872                 7,087,872\n",
       "│    └─DecoderBlock: 2-10                               [1, 1024, 768]            7,087,872                 7,087,872\n",
       "│    └─DecoderBlock: 2-11                               [1, 1024, 768]            7,087,872                 7,087,872\n",
       "│    └─DecoderBlock: 2-12                               [1, 1024, 768]            7,087,872                 7,087,872\n",
       "├─Sequential: 1-3                                       [1, 1024, 50257]          --                        --\n",
       "│    └─LayerNorm: 2-13                                  [1, 1024, 768]            1,536                     1,536\n",
       "│    └─Linear: 2-14                                     [1, 1024, 50257]          38,647,633                38,647,633\n",
       "==================================================================================================================================\n",
       "Total params: 163,087,441\n",
       "Trainable params: 163,087,441\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 162.30\n",
       "==================================================================================================================================\n",
       "Input size (MB): 205.85\n",
       "Forward/backward pass size (MB): 1254.76\n",
       "Params size (MB): 649.20\n",
       "Estimated Total Size (MB): 2109.82\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T04:47:05.794919Z",
     "start_time": "2024-10-15T04:47:03.323066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import GPT2Config, GPT2Model\n",
    "config = GPT2Config()\n",
    "gpt1_torch_model = GPT2Model(config)\n",
    "\n",
    "input_tensor = torch.randint(0, word_dim, (1, seq_len), dtype=torch.long) \n",
    "summary(gpt1_torch_model, input_data=input_tensor, device='cpu', col_names=['output_size', 'num_params', 'mult_adds'], depth=2)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #                   Mult-Adds\n",
       "========================================================================================================================\n",
       "GPT2Model                                     [1, 12, 1024, 64]         --                        --\n",
       "├─Embedding: 1-1                              [1, 1024, 768]            38,597,376                38,597,376\n",
       "├─Embedding: 1-2                              [1, 1024, 768]            786,432                   786,432\n",
       "├─Dropout: 1-3                                [1, 1024, 768]            --                        --\n",
       "├─ModuleList: 1-4                             --                        --                        --\n",
       "│    └─GPT2Block: 2-1                         [1, 1024, 768]            7,087,872                 13,605,473,280\n",
       "│    └─GPT2Block: 2-2                         [1, 1024, 768]            7,087,872                 13,605,473,280\n",
       "│    └─GPT2Block: 2-3                         [1, 1024, 768]            7,087,872                 13,605,473,280\n",
       "│    └─GPT2Block: 2-4                         [1, 1024, 768]            7,087,872                 13,605,473,280\n",
       "│    └─GPT2Block: 2-5                         [1, 1024, 768]            7,087,872                 13,605,473,280\n",
       "│    └─GPT2Block: 2-6                         [1, 1024, 768]            7,087,872                 13,605,473,280\n",
       "│    └─GPT2Block: 2-7                         [1, 1024, 768]            7,087,872                 13,605,473,280\n",
       "│    └─GPT2Block: 2-8                         [1, 1024, 768]            7,087,872                 13,605,473,280\n",
       "│    └─GPT2Block: 2-9                         [1, 1024, 768]            7,087,872                 13,605,473,280\n",
       "│    └─GPT2Block: 2-10                        [1, 1024, 768]            7,087,872                 13,605,473,280\n",
       "│    └─GPT2Block: 2-11                        [1, 1024, 768]            7,087,872                 13,605,473,280\n",
       "│    └─GPT2Block: 2-12                        [1, 1024, 768]            7,087,872                 13,605,473,280\n",
       "├─LayerNorm: 1-5                              [1, 1024, 768]            1,536                     1,536\n",
       "========================================================================================================================\n",
       "Total params: 124,439,808\n",
       "Trainable params: 124,439,808\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 163.31\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 849.35\n",
       "Params size (MB): 497.76\n",
       "Estimated Total Size (MB): 1347.11\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  }
 ]
}
